## Tabular Methods in RL
This repository contains reinforcement learning algoithms applied to tabular environments.
Tabular methods refers to problems in which the state and actions spaces are small enough to approximate value functions in form of arrays and tables.

## Algorithms Used
* *[Dynamic programming](https://towardsdatascience.com/planning-by-dynamic-programming-reinforcement-learning-ed4924bbaa4c#:~:text=Dynamic%20programming%20can%20be%20used,%2C%20reward%20structure%20etc.).)* : Dynamic programming algorithms solve a category of problems called planning problems. Classical DP algorithms are of limited utility in reinforcement learning both because of their assumption of a perfect model and because of their great computational expense.

* *SARSA and Temporal Difference* : Temporal difference (TD) learning refers to a class of [model-free reinforcement learning](https://en.wikipedia.org/wiki/Model-free_(reinforcement_learning)) methods which learn by [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) from the current estimate of the value function. These methods sample from the environment, like [Monte Carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method), and perform updates based on current estimates, like dynamic programming methods.


